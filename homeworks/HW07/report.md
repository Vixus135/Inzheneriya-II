# HW07 – Report

## 1. Datasets

Были выбраны 3 датасета из 4:

- Dataset‑01 
- Dataset‑03 
- Dataset‑04

### 1.1 Dataset A
- Файл: `hw07_ds1.csv`
- Размер: 500 строк, 10 столбцов
- Признаки: все числовые
- Пропуски: отсутствуют
- "Подлости" датасета: признаки в разных шкалах, есть умеренные выбросы, плотность точек неравномерная. Без масштабирования KMeans работает хуже

### 1.2 Dataset B

- Файл: `hw07_ds3.csv`
- Размер: 600 строк, 12 столбцов
- Признаки: все числовые
- Пропуски: отсутствуют
- "Подлости" датасета: плотные группы, но с разной формой; без масштабирования расстояния искажаются. Кластеры довольно хорошо разделяются после PCA

### 1.3 Dataset C

- Файл: `hw07_ds4.csv`
- Размер: 700 строк, 15 столбцов
- Признаки: в основном категориальные.После OneHotEncoder превращаются в десятки бинарных признаков
- Пропуски: нет
- "Подлости" датасета: высокая размерность, разреженность, бинарные признаки (DBSCAN плохо работает, расстояния между объектами почти одинаковые)

## 2. Protocol

**Препроцессинг:**

- Для числовых данных: `StandardScaler` 
- Для категориальных: `OneHotEncoder` 
- Пропусков не было 
- PCA использовался только для визуализации

**Поиск гиперпараметров:**

- KMeans: `k` в диапазоне 2–20, фиксировали `random_state=42`, `n_init=10` 
- DBSCAN: `eps = {0.1, 0.2, 0.3, 0.5}`, `min_samples = {3, 5, 10}`

**Критерии выбора лучшего решения:**

- основной ориентир — `silhouette` 
- дополнительно смотрели на `davies_bouldin_score` и `calinski_harabasz_score` 
- для DBSCAN учитывали долю шума

**Визуализация:**

- PCA для каждого лучшего решения 
- графики подбора параметров: silhouette vs k и silhouette vs eps

## 3. Models

На каждом датасете сравнивались: 
- **KMeans** 
    - подбирали `k` 
    - фиксировали `random_state=42` и `n_init=10` 
- **DBSCAN** 
    - подбирали `eps` и `min_samples` 
    - анализировали долю шума
    
Дополнительных методов не использовалось.

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, при `k = 5`
- Метрики (silhouette / DB / CH): 
    - silhouette = 0.41 
    - DB = 0.88 
    - CH = 312.5
- DBSCAN: давал много шума и нестабильные разбиения
- Коротко: данные компактные, хорошо разделяются в PCA, поэтому KMeans стабильно находит центры. Метрики подтверждают, что разбиение разумное

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, при `k = 4`
- Метрики (silhouette / DB / CH):
    - silhouette = 0.52 
    - DB = 0.73 
    - CH = 420.1
- DBSCAN: чувствителен к eps — либо много шума, либо один кластер
- Коротко: структура кластеров хорошо выражена, KMeans даёт одинаковые результаты при разных random_state (ARI = 1.0), что говорит о стабильности

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, при `k = 6`
- Метрики (silhouette / DB / CH):
    - silhouette = 0.38  
    - DB = 0.95  
    - CH = 280.3  
- DBSCAN: не нашёл валидных кластеров (всё шум или один кластер)  
- Коротко: после OneHotEncoder признаки становятся бинарными и расстояния почти одинаковые из-за чего DBSCAN не работает. KMeans оказался единственным рабочим вариантом

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans ломается на данных с разреженными бинарными признаками (dataset‑04) 
- DBSCAN выигрывает только там, где есть плотные группы и расстояния хорошо отражают структуру 
- Масштабирование сильно влияет на оба метода — без него silhouette падает 
- Категориальные признаки после OHE делают пространство слишком равномерным для DBSCAN
- Выбросы тоже мешают DBSCAN — он начинает считать их шумом и портит метрики

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 5 запусков KMeans с разными `random_state`
- ARI между всеми парами запусков = 1.0 
- Алгоритм каждый раз выдаёт одно и то же разбиение
- Кластеры в dataset‑03 хорошо выражены, и KMeans сходится в одно решение независимо от инициализации 
- **Вывод:** модель полностью устойчива на этом датасете

### 5.3 Интерпретация кластеров

- Смотрели на средние значения признаков внутри каждого кластера 
- В dataset‑01 и dataset‑03 кластеры различались по ключевым числовым признакам
- В dataset‑04 различия отражали комбинации категориальных признаков после OHE
- В целом кластеры получились интерпретируемыми, особенно после PCA

## 6. Conclusion

- Масштабирование оказалось очень важным шагом: без него и KMeans, и DBSCAN работали заметно хуже, потому что признаки были в разных диапазонах
- Метрика silhouette хорошо помогает выбрать подходящее число кластеров, но полезно дополнительно смотреть на Davies–Bouldin и Calinski–Harabasz, чтобы убедиться, что разбиение действительно качественное
- DBSCAN плохо справляется с разреженными данными после OneHotEncoder — расстояния между объектами становятся почти одинаковыми, и алгоритм либо видит один большой кластер, либо считает почти всё шумом
- KMeans показывает хорошие результаты, когда кластеры действительно существуют и более‑менее компактны. В таких случаях он работает стабильно и предсказуемо
