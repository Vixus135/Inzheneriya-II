## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-03.csv`
- Размер: 15000 строк, 30 столбцов
- Целевая переменная: `target`  
    Классы: 0, 1, 2 
    Доли классов: 
    - класс 0: 54.25% 
    - класс 1: 30.23% 
    - класс 2: 15.51%
- Признаки: 28 числовых признаков (f01–f28)(Столбец id исключён из признаков).
Пропусков нет


## 2. Protocol

- Разбиение: train/test = 80% / 20%, `random_state=42`, `stratify=y`.
- Подбор: Использовался `GridSearchCV` с **5‑fold StratifiedKFold**, оптимизация по метрике **f1_macro**
- Метрики: 
- **accuracy** — базовая метрика для мультикласса 
- **f1_macro** — учитывает качество по каждому классу и не даёт «завалить» редкие классы 
- **OVR** — мультиклассовый вариант ROC-AUC, рассчитан только для моделей, поддерживающих `predict_proba`

## 3. Models
Сравнивались следующие модели: 
### Baseline 
- **DummyClassifier** (`most_frequent`) — нижняя граница качества 
- **LogisticRegression** (через Pipeline: StandardScaler + LogisticRegression) 
### Модели недели 6 
- **DecisionTreeClassifier** Подбирались: `max_depth`, `min_samples_leaf`, `min_samples_split` 
- **RandomForestClassifier** Подбирались: `n_estimators`, `max_depth`, `min_samples_leaf`, `max_features` 
- **GradientBoostingClassifier** Подбирались: `n_estimators`, `learning_rate`, `max_depth`, `min_samples_leaf` 
 
## 4. Results
Финальные метрики на **test**:
| Model | Accuracy | F1-macro | 
|---|---|---| 
| DummyClassifier | 0.54 | 0.24 |
|LogisticRegression | 0.72| 0.67 | 
| DecisionTree | 0.8 | 0.75 | 
| RandomForest | 0.89 | 0.86 | 
| GradientBoosting | 0.88 | 0.85 |

**Победитель:** *RandomForest* (по метрике f1_macro). Он показывает наилучшее качество тк хорошо справляется с мультиклассовой задачей и устойчив к шуму

## 5. Analysis
- Устойчивость: ансамблевые модели (RandomForest, GradientBoosting) показывают стабильные результаты:
при изменении random_state метрики меняются незначительно (обычно в пределах ±0.01).
- Ошибки:
Confusion matrix для RandomForest показывает:
    - модель хорошо различает все три класса,
    - наибольшее количество ошибок — между классами 1 и 2 (тк они ближе по структуре признаков),
    - сильного перекоса в пользу одного класса нет.
- Интерпретация:
Топ‑15 признаков по permutation importance:
    - f13
    - f05
    - f28
    - f01
    - f10
    - f18
    - f12
    - f15
    - f17
    - f27
    - f07
    - f11
    - f06
    - f25
    - f22

RandomForest хорошо показывает, какие признаки важнее, поэтому по нему удобно понимать, что происходит внутри данных.
Так самыми важными оказались признаки f13, f05, f28 и f01 — модель сильнее всего опирается именно на них при разделении классов, но так же есть и признаки, которые можно смело удалять, тк качество модели не измениться (ну либо слабо измениться)

## 6. Conclusion

Деревья решений сами по себе часто переобучаются: если им не ограничивать глубину или размер листьев, они начинают «запоминать» данные вместо того, чтобы учиться общим закономерностям. Поэтому важно контролировать их сложность, иначе качество на тесте падает

Ансамблевые методы, такие как RandomForest и GradientBoosting, работают заметно лучше одиночных деревьев. Они объединяют много слабых моделей, и за счёт этого итоговое предсказание получается более устойчивым и точным. В моём эксперименте это хорошо видно: ансамбли дают ощутимый прирост по accuracy и f1_macro.

Благодаря рermutation importance можно понять, какие признаки действительно влияют на решение модели. Это удобный способ интерпретации, тк сразу видно какие фичи важные, а какие почти ничего не дают и могут быть исключены

При соблюдении честного ML‑протокола(фиксированный train/test, подбор параметров только на train, использование одинаковых метрик) можно сравнивать модели корректно. Без этого можно получить значения, не отражающие реальное качество модели, а так для "галочки"